{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from fastai.script import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "from fastai.distributed import *\n",
    "from fastprogress import fastprogress\n",
    "from torchvision.models import *\n",
    "from fastai.vision.models import *\n",
    "from pathlib import Path\n",
    "\n",
    "from mmdet.models.backbones import *\n",
    "from mmdet.models.backbones.base_backbone import ClassifierPretrainWrapper\n",
    "\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "fastprogress.MAX_COLS = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(size, woof, bs, workers=None):\n",
    "    if   size <= 128:\n",
    "        path = URLs.IMAGEWOOF_160 if woof else URLs.IMAGENETTE_160\n",
    "    elif size <= 224: \n",
    "        path = URLs.IMAGEWOOF_320 if woof else URLs.IMAGENETTE_320\n",
    "    else:\n",
    "        path = URLs.IMAGEWOOF if woof else URLs.IMAGENETTE\n",
    "    path = untar_data(path)\n",
    "\n",
    "    n_gpus = num_distrib() or 1\n",
    "    if workers is None:\n",
    "        workers = min(8, num_cpus() // n_gpus)\n",
    "\n",
    "    return (ImageList\n",
    "            .from_folder(path)\n",
    "            .split_by_folder(valid='val')\n",
    "            .label_from_folder()\n",
    "            .transform(([flip_lr(p=0.5), cutout(n_holes=(1, 4), length=(10, 160), p=0.5)], []), size=size)\n",
    "            .databunch(bs=bs, num_workers=workers)\n",
    "            .presize(size, scale=(0.35, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes: Param(\"Class count\", int) = 10\n",
    "arch_name: Param(\"Backbone name, used for dumping\", str) = 'scarlet_a'\n",
    "\n",
    "# Model description\n",
    "backbone = ScarletA(out_indices=None)\n",
    "model = ClassifierPretrainWrapper(backbone, input_channels=1280, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001; eff_lr: 0.0005; size: 320; alpha: 0.99; mom: 0.9; eps: 1e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='20', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/20 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>top_k_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='97', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/97 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gpu: Param(\"GPU to run on\", str) = None\n",
    "woof: Param(\"Use imagewoof (otherwise imagenette)\", int) = True\n",
    "lr: Param(\"Learning rate\", float) = 1e-3\n",
    "size: Param(\"Size (px: 128, 192, 224)\", int) = 320\n",
    "alpha: Param(\"Alpha\", float) = 0.99\n",
    "mom: Param(\"Momentum\", float) = 0.9\n",
    "eps: Param(\"epsilon\", float) = 1e-6\n",
    "epochs: Param(\"Number of epochs\", int) = 20\n",
    "bs: Param(\"Batch size\", int) = 64\n",
    "mixup: Param(\"Mixup\", float) = 0.\n",
    "opt: Param(\"Optimizer (adam, rms, sgd)\", str) = 'adam'\n",
    "dump: Param(\"Path to pretrained backbones\", Path) = '/mnt/nfs/Other/pytorch_pretrained_backbones/'\n",
    "\n",
    "gpu = setup_distrib(gpu)\n",
    "if gpu is None: \n",
    "    bs *= torch.cuda.device_count()\n",
    "\n",
    "if opt=='adam':\n",
    "    opt_func = partial(optim.Adam, betas=(mom, alpha), eps=eps)\n",
    "elif opt=='rms':\n",
    "    opt_func = partial(optim.RMSprop, alpha=alpha, eps=eps)\n",
    "elif opt=='sgd':\n",
    "    opt_func = partial(optim.SGD, momentum=mom)\n",
    "\n",
    "data = get_data(size, woof, bs)\n",
    "bs_rat = bs / 256\n",
    "if gpu is not None:\n",
    "    bs_rat *= num_distrib()\n",
    "if not gpu:\n",
    "    print(f'lr: {lr}; eff_lr: {lr * bs_rat}; size: {size}; alpha: {alpha}; mom: {mom}; eps: {eps}')\n",
    "lr *= bs_rat\n",
    "\n",
    "learn = Learner(data, model, wd=1e-2, opt_func=opt_func,\n",
    "                metrics=[accuracy, top_k_accuracy],\n",
    "                bn_wd=False, true_wd=True,\n",
    "                loss_func=LabelSmoothingCrossEntropy())\n",
    "if mixup: \n",
    "    learn = learn.mixup(alpha=mixup)\n",
    "learn = learn.to_fp16(dynamic=True)\n",
    "if gpu is None:      \n",
    "    learn.to_parallel()\n",
    "elif num_distrib() > 1: \n",
    "    learn.to_distributed(gpu) # Requires `-m fastai.launch`\n",
    "\n",
    "learn.fit_one_cycle(epochs, lr, div_factor=10, pct_start=0.3)\n",
    "\n",
    "if not (dump / arch_name).exists():\n",
    "    os.makedirs(str(dump / arch_name))\n",
    "learn.model.save_backbone(dump / arch_name / f\"{arch_name}__{datetime.now().strftime('%d_%m_%y__%H_%M_%S')}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
